from __future__ import annotations
from typing import AsyncGenerator
import httpx
from fastapi import APIRouter, HTTPException, Depends, status
from loguru import logger

from app.models.schemas import (
    ChatRequest, ChatResponse, ODataGetRequest, ODataPostRequest,
)
from app.services.odata_client import ODataService

# Optional NLP imports (app should still boot without NLP stack)
try:
    from app.services.nlp_router import (
        available as nlp_available,
        parse_to_intent,
        chat_general as nlp_chat_general,
    )
except Exception:
    def nlp_available() -> bool:  # type: ignore
        return False
    parse_to_intent = None        # type: ignore
    nlp_chat_general = None       # type: ignore

# IMPORTANT:
# aggregator mounts us with: include_router(chat_router, prefix="/chat", tags=["chat"])
# so keep path "" here to expose POST /api/chat
router = APIRouter()

# Proper dependency that guarantees httpx client cleanup
async def get_service() -> AsyncGenerator[ODataService, None]:
    svc = ODataService()
    try:
        yield svc
    finally:
        try:
            await svc.aclose()
        except Exception as e:
            logger.warning(f"Failed to close ODataService client: {e}")

@router.post("", response_model=ChatResponse)
async def chat(req: ChatRequest, service: ODataService = Depends(get_service)):
    # Ensure NLP is available
    try:
        if not nlp_available():
            raise HTTPException(status_code=503, detail="NLP (LangChain) is disabled or unavailable")
    except HTTPException:
        raise
    except Exception as e:
        logger.exception("NLP availability check failed")
        raise HTTPException(status_code=503, detail=f"NLP unavailable: {e}")

    # Try to parse an OData intent; if that fails, treat as general chat
    try:
        nlp = parse_to_intent(req.message)  # type: ignore
        intent = (nlp.intent_json or {}).get("intent", "").lower()
    except Exception:
        if nlp_chat_general is None:
            raise HTTPException(status_code=400, detail="NLP parsing failed and no general chat available")
        text = nlp_chat_general(req.message).text  # <-- ensure string
        return ChatResponse(ok=True, stage="general", intent="general", result={"text": text})

    # If the parser explicitly said "general", route to general chat
    if intent == "general":
        if nlp_chat_general is None:
            raise HTTPException(status_code=400, detail="General chat unavailable")
        text = nlp_chat_general(req.message).text
        return ChatResponse(ok=True, stage="general", intent="general", result={"text": text})

    # Optional policy guard
    intent_json = nlp.intent_json
    if req.allowed_services and intent_json.get("service") not in set(req.allowed_services):
        raise HTTPException(status_code=403, detail="Service not allowed by policy")

    kind = intent

    # -------- GET --------
    if kind == "get":
        try:
            get_body = ODataGetRequest(
                service=intent_json["service"],
                entity=intent_json["entity"],
                fields=intent_json.get("fields"),
                filters=intent_json.get("filters"),
                top=intent_json.get("top", 100),
                skip=intent_json.get("skip", 0),
                orderby=intent_json.get("orderby"),
            )
            data = await service.execute_get(get_body)
            return ChatResponse(ok=True, stage="get", intent="get", nlp_json=intent_json, result=data)
        except httpx.HTTPStatusError as e:
            code = e.response.status_code if e.response else 502
            detail = e.response.text if e.response else str(e)
            logger.exception("GET failed with upstream status %s", code)
            raise HTTPException(status_code=code, detail=detail)
        except Exception as e:
            logger.exception("GET failed")
            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))

    # ----- CREATE / UPDATE -----
    if kind in ("create", "update"):
        try:
            post_body = ODataPostRequest(
                action="create" if kind == "create" else "update",
                service=intent_json["service"],
                entity=intent_json["entity"],
                key_fields=intent_json.get("key_fields"),
                payload=intent_json.get("payload") or {},
                confirm=bool(intent_json.get("confirm", False) or req.confirm),
            )

            # Preview-first unless explicitly disabled
            if req.preview_only:
                preview = await service.preview_post(post_body)
                return ChatResponse(
                    ok=True,
                    stage="preview",
                    intent=kind,
                    nlp_json=intent_json,
                    resolved_endpoint=preview.url,
                    result=preview.model_dump(),
                )

            if not post_body.confirm:
                raise HTTPException(status_code=400, detail="confirm must be true to execute create/update")

            data = await service.execute_post(post_body)
            return ChatResponse(ok=True, stage="executed", intent=kind, nlp_json=intent_json, result=data)

        except httpx.HTTPStatusError as e:
            code = e.response.status_code if e.response else 502
            detail = e.response.text if e.response else str(e)
            logger.exception("POST failed with upstream status %s", code)
            raise HTTPException(status_code=code, detail=detail)
        except Exception as e:
            logger.exception("POST failed")
            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))

    # Unsupported intent â†’ treat as general chat instead of 400
    if nlp_chat_general is not None:
        text = nlp_chat_general(req.message).text
        return ChatResponse(ok=True, stage="general", intent="general", result={"text": text})
    raise HTTPException(status_code=400, detail="Unsupported intent")

@router.post("/general", response_model=ChatResponse)
async def general_chat(req: ChatRequest):
    """General conversational chat (no OData execution)."""
    try:
        if not nlp_available() or nlp_chat_general is None:
            raise HTTPException(status_code=503, detail="NLP (LangChain) is disabled or unavailable")
    except HTTPException:
        raise
    except Exception as e:
        logger.exception("NLP availability check failed")
        raise HTTPException(status_code=503, detail=f"NLP unavailable: {e}")

    try:
        text = nlp_chat_general(req.message).text  # <-- ensure string
        return ChatResponse(ok=True, stage="general", intent="general", result={"text": text})
    except Exception as e:
        logger.exception("General chat failed")
        raise HTTPException(status_code=500, detail=str(e))
